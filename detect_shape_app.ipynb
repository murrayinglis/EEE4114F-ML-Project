{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Canvas, Button\n",
    "from PIL import Image, ImageDraw, ImageOps, ImageTk\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(28800, 512)  # Adjust size according to your image dimension / pooling\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: triangle\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the saved model\n",
    "state_dict = torch.load('model_k2_fold0.pth', map_location=device)\n",
    "model = SimpleCNN()  # Instantiate your model class\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "# Step 2: Prepare the input data (image tensor)\n",
    "# Load your image\n",
    "image_path = 'shape.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Get std and mean\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "img = img.astype(np.float32) / 255.0\n",
    "pixel_sum = np.sum(img)\n",
    "pixel_count = img.size\n",
    "mean = pixel_sum / pixel_count\n",
    "variance = np.sum((img - mean) ** 2)\n",
    "std = np.sqrt(variance / pixel_count)\n",
    "\n",
    "# Step 3: Preprocess the input data if necessary\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((240, 240)),  # Resize to match model input size\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize\n",
    "])\n",
    "\n",
    "# Apply transformations to the image\n",
    "input_image = transform(image)\n",
    "input_image = input_image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Step 4: Pass the input data through the model\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)\n",
    "\n",
    "# Step 5: Interpret the output\n",
    "# For example, if it's a classification model, you might want to get the predicted class\n",
    "_, predicted_class = output.max(1)\n",
    "labels_map = {\n",
    "    \"circle\": 0,\n",
    "    \"square\": 1,\n",
    "    \"triangle\": 2,\n",
    "    \"pentagon\": 3,\n",
    "    \"hexagon\": 4,\n",
    "}\n",
    "reverse_labels_map = {value: key for key, value in labels_map.items()}\n",
    "predicted_label = reverse_labels_map[predicted_class.item()]\n",
    "\n",
    "print(\"Predicted class:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: square\n",
      "Predicted class: circle\n",
      "Predicted class: circle\n",
      "Predicted class: triangle\n",
      "Predicted class: square\n",
      "Predicted class: pentagon\n",
      "Predicted class: pentagon\n",
      "Predicted class: pentagon\n",
      "Predicted class: hexagon\n",
      "Predicted class: circle\n",
      "Predicted class: circle\n",
      "Predicted class: circle\n",
      "Predicted class: triangle\n",
      "Predicted class: circle\n",
      "Predicted class: triangle\n",
      "Predicted class: triangle\n",
      "Predicted class: square\n",
      "Predicted class: triangle\n",
      "Predicted class: circle\n",
      "Predicted class: circle\n",
      "Predicted class: hexagon\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "    \"circle\": 0,\n",
    "    \"square\": 1,\n",
    "    \"triangle\": 2,\n",
    "    \"pentagon\": 3,\n",
    "    \"hexagon\": 4,\n",
    "}\n",
    "reverse_labels_map = {value: key for key, value in labels_map.items()}\n",
    "\n",
    "class DrawingApp():\n",
    "    def __init__(self, master, width=240, height=240):\n",
    "\n",
    "        self.mode = 0\n",
    "        self.label = \"circle\"\n",
    "        self.master = master\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "        self.canvas = tk.Canvas(master, width=self.width, height=self.height, bg=\"white\")\n",
    "        self.canvas.pack()\n",
    "        \n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw)\n",
    "        \n",
    "        self.button_predict = tk.Button(master, text=\"Predict\", command=self.predict, bg=\"cyan\")\n",
    "        self.button_predict.pack()\n",
    "\n",
    "        self.label_text = tk.StringVar()\n",
    "        self.label_text.set(\"Draw Shape\")  # Initial label text\n",
    "        self.label_widget = tk.Label(master, textvariable=self.label_text)\n",
    "        self.label_widget.pack()\n",
    "        \n",
    "        self.new_canvas()  # Create a new drawing canvas\n",
    "            \n",
    "    def draw(self, event):\n",
    "        x, y = event.x, event.y\n",
    "        r = 3\n",
    "        self.canvas.create_oval(x-r, y-r, x+r, y+r, fill=\"black\")\n",
    "        self.draw.ellipse([x-r, y-r, x+r, y+r], fill=\"black\")\n",
    "        \n",
    "    def predict(self):\n",
    "        filename = \"your_shape.png\"\n",
    "        self.image.save(filename)\n",
    "\n",
    "        image_path = filename\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert('L')\n",
    "\n",
    "        # Get std and mean\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        pixel_sum = np.sum(img)\n",
    "        pixel_count = img.size\n",
    "        mean = pixel_sum / pixel_count\n",
    "        variance = np.sum((img - mean) ** 2)\n",
    "        std = np.sqrt(variance / pixel_count)\n",
    "\n",
    "        # Define transformations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((240, 240)),  # Resize to match model input size\n",
    "            transforms.ToTensor(),           # Convert to tensor\n",
    "            transforms.Normalize(mean=mean, std=std)  # Normalize\n",
    "        ])\n",
    "\n",
    "        # Apply transformations to the image\n",
    "        input_image = transform(image)\n",
    "        input_image = input_image.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        state_dict = torch.load('model_k2_fold0.pth', map_location=device)\n",
    "        model = SimpleCNN()  # Instantiate your model class\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_image)\n",
    "\n",
    "        # Step 5: Interpret the output\n",
    "        # For example, if it's a classification model, you might want to get the predicted class\n",
    "        _, predicted_class = output.max(1)\n",
    "        predicted_label = reverse_labels_map[predicted_class.item()]\n",
    "\n",
    "        print(\"Predicted class:\", predicted_label)\n",
    "        self.label_text.set(predicted_label)\n",
    "\n",
    "        self.new_canvas()  # Create a new drawing canvas\n",
    "        \n",
    "    def new_canvas(self):\n",
    "        self.canvas.delete(\"all\")  # Clear the canvas\n",
    "        self.image = Image.new(\"RGB\", (self.width, self.height), \"white\")\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Draw Shapes\")\n",
    "    app = DrawingApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
