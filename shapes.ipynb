{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate shape pngs\n",
    "Transparent background so can be overlayed over other random backgrounds. Random colour. Random size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_circles(num_images):\n",
    "    \"\"\"\n",
    "    Generate PNG images of circles with random radius, color and position.\n",
    "    \n",
    "    Parameters:\n",
    "        num_images (int): Number of PNG images to generate.\n",
    "    \"\"\"\n",
    "    for i in range(1, num_images + 1):\n",
    "        # Generate random radius and color\n",
    "        radius = np.random.uniform(0.1, 0.5)  # Random radius between 0.1 and 0.5\n",
    "        color = np.random.rand(3,)  # Random RGB color\n",
    "        pos1 = np.random.uniform(0.3, 0.7)\n",
    "        pos2 = np.random.uniform(0.3, 0.7)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        circle_outer = plt.Circle((pos1, pos2), radius, color=color, fill=False, linewidth =2)\n",
    "        ax.add_artist(circle_outer)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')  # Turn off axes\n",
    "        fig.set_size_inches(224/100, 224/100)\n",
    "        filename = f\"Raw shapes/circle{i}.png\"\n",
    "        fig.savefig(filename, dpi=100, bbox_inches='tight', transparent=True)\n",
    "        #plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "gen_circles(5)  # Generates 5 PNG images: circle1.png, circle2.png, ..., circle5.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_squares(num_images):\n",
    "    \"\"\"\n",
    "    Generate PNG images of circles with random radius, color and position.\n",
    "    \n",
    "    Parameters:\n",
    "        num_images (int): Number of PNG images to generate.\n",
    "    \"\"\"\n",
    "    sf = 0.975\n",
    "    for i in range(1, num_images + 1):\n",
    "        # Generate random radius and color\n",
    "        length1 = np.random.uniform(0.1, 0.5) # Random length between 0.1 and 0.5\n",
    "        length2 = length1 + np.random.uniform(-0.02, 0.02) # Make other length have some variance\n",
    "        color = np.random.rand(3,)  # Random RGB color\n",
    "        pos1 = np.random.uniform(0.3, 0.7)\n",
    "        pos2 = np.random.uniform(0.3, 0.7)\n",
    "        angle = np.random.uniform(0,360)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        square_outer = plt.Rectangle((pos1, pos2), length1, length2, color=color, fill=False, angle=angle)\n",
    "        ax.add_artist(square_outer)\n",
    "        #ax.add_artist(square_inner)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')  # Turn off axes\n",
    "        filename = f\"Raw shapes/square{i}.png\"\n",
    "        fig.set_size_inches(224/100, 224/100)\n",
    "        fig.savefig(filename, dpi=100, bbox_inches='tight', transparent=True)\n",
    "        #plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "gen_squares(5)  # Generates 5 PNG images: circle1.png, circle2.png, ..., circle5.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_triangles(num_images):\n",
    "    \"\"\"\n",
    "    Generate PNG images of random triangles with random colors.\n",
    "    \n",
    "    Parameters:\n",
    "        num_images (int): Number of PNG images to generate.\n",
    "    \"\"\"\n",
    "    for i in range(1, num_images + 1):\n",
    "        # Generate random vertices for the triangle\n",
    "        vertices = np.random.rand(3, 2)  # Generate 3 random (x, y) coordinates\n",
    "        \n",
    "        # Generate a random color for the triangle\n",
    "        color = np.random.rand(3,)  # Random RGB color\n",
    "        \n",
    "        # Create a Polygon patch using the generated vertices\n",
    "        triangle = Polygon(vertices, closed=True, color=color, fill=False)\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        # Add triangle to plot\n",
    "        ax.add_patch(triangle)\n",
    "        \n",
    "        # Set plot properties\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')  # Turn off axes\n",
    "        \n",
    "        # Save plot as PNG\n",
    "        filename = f\"Raw shapes/triangle{i}.png\"\n",
    "        fig.set_size_inches(224/100, 224/100)\n",
    "        fig.savefig(filename, dpi=100, bbox_inches='tight', transparent=True)\n",
    "        \n",
    "        # Close plot\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "gen_triangles(5)  # Generates 5 PNG images of random triangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pentagons(num_images):\n",
    "    \"\"\"\n",
    "    Generate PNG images of random pentagons with random colors.\n",
    "    \n",
    "    Parameters:\n",
    "        num_images (int): Number of PNG images to generate.\n",
    "    \"\"\"\n",
    "    for i in range(1, num_images + 1):\n",
    "        # Generate random vertices for the pentagon\n",
    "        angle = 2 * np.pi / 5\n",
    "        rotation = np.random.rand() * 2 * np.pi  # Random rotation\n",
    "        vertices = np.array([[np.cos(rotation + j * angle), np.sin(rotation + j * angle)] for j in range(5)])\n",
    "        # Scale and translate the pentagon to fit inside [0, 1] x [0, 1] square\n",
    "        vertices = (vertices - vertices.min(axis=0)) / (vertices.max(axis=0) - vertices.min(axis=0))\n",
    "\n",
    "        # Generate random scaling factors for x and y axes\n",
    "        scale_factors = np.random.rand(2,) * 0.8 + 0.2  # Random scale factors between 0.2 and 1.0\n",
    "        vertices[:, 0] *= scale_factors[0]\n",
    "        vertices[:, 1] *= scale_factors[1]\n",
    "        \n",
    "        # Generate a random color for the pentagon\n",
    "        color = np.random.rand(3,)  # Random RGB color\n",
    "        \n",
    "        # Create a Polygon patch using the generated vertices\n",
    "        pentagon = Polygon(vertices, closed=True, color=color, fill=False)\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        # Add pentagon to plot\n",
    "        ax.add_patch(pentagon)\n",
    "        \n",
    "        # Set plot properties\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')  # Turn off axes\n",
    "        \n",
    "        # Save plot as PNG\n",
    "        filename = f\"Raw shapes/pentagon{i}.png\"\n",
    "        fig.set_size_inches(224/100, 224/100)\n",
    "        fig.savefig(filename, dpi=100, bbox_inches='tight', transparent=True)\n",
    "        \n",
    "        # Close plot\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "gen_pentagons(5)  # Generates 5 PNG images of random pentagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_hexagons(num_images):\n",
    "    \"\"\"\n",
    "    Generate PNG images of random hexagons with random sizes and colors.\n",
    "    \n",
    "    Parameters:\n",
    "        num_images (int): Number of PNG images to generate.\n",
    "    \"\"\"\n",
    "    for i in range(1, num_images + 1):\n",
    "        # Generate random vertices for the hexagon\n",
    "        angle = 2 * np.pi / 6\n",
    "        rotation = np.random.rand() * 2 * np.pi  # Random rotation\n",
    "        vertices = np.array([[np.cos(rotation + j * angle), np.sin(rotation + j * angle)] for j in range(6)])\n",
    "        \n",
    "        # Translate the hexagon to fit inside [0, 1] x [0, 1] square\n",
    "        vertices = (vertices - vertices.min(axis=0)) / (vertices.max(axis=0) - vertices.min(axis=0))\n",
    "\n",
    "        # Generate random scaling factors for x and y axes\n",
    "        scale_factors = np.random.rand(2,) * 0.8 + 0.2  # Random scale factors between 0.2 and 1.0\n",
    "        vertices[:, 0] *= scale_factors[0]\n",
    "        vertices[:, 1] *= scale_factors[1]\n",
    "\n",
    "        # Generate a random color for the hexagon\n",
    "        color = np.random.rand(3,)  # Random RGB color\n",
    "        \n",
    "        # Create a Polygon patch using the generated vertices\n",
    "        hexagon = Polygon(vertices, closed=True, color=color, fill=False)\n",
    "        \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        # Add hexagon to plot\n",
    "        ax.add_patch(hexagon)\n",
    "        \n",
    "        # Set plot properties\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')  # Turn off axes\n",
    "        \n",
    "        # Save plot as PNG\n",
    "        filename = f\"Raw shapes/hexagon{i}.png\"\n",
    "        fig.set_size_inches(224/100, 224/100)\n",
    "        fig.savefig(filename, dpi=100, bbox_inches='tight', transparent=True)\n",
    "        \n",
    "        # Close plot\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "gen_hexagons(5)  # Generates 5 PNG images of random hexagons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlaying over backgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am overlaying the shapes over some pictures I took of different white paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_images(background_path, overlay_path, output_path):\n",
    "    try:\n",
    "        # Open background and overlay images\n",
    "        background = Image.open(background_path)\n",
    "        overlay = Image.open(overlay_path)\n",
    "\n",
    "        # Convert overlay image to RGBA mode if it's not already\n",
    "        if overlay.mode != 'RGBA':\n",
    "            overlay = overlay.convert('RGBA')\n",
    "\n",
    "        # Resize overlay image to 224x224 pixels\n",
    "        overlay = overlay.resize((224, 224))\n",
    "\n",
    "        # Resize background image to 224x224 pixels\n",
    "        background = background.resize((224, 224))\n",
    "\n",
    "        # Calculate the maximum allowed starting positions for the overlay\n",
    "        max_x = 0\n",
    "        max_y = 0\n",
    "\n",
    "        # Choose a random starting position for the overlay\n",
    "        start_x = np.random.randint(0, max_x + 1)\n",
    "        start_y = np.random.randint(0, max_y + 1)\n",
    "\n",
    "        # Paste the overlay image onto the background image\n",
    "        background.paste(overlay, (start_x, start_y), overlay)\n",
    "\n",
    "        # Check if the output directory exists, if not, create it\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Save the output image\n",
    "        background.save(output_path)\n",
    "        #print(\"Image saved successfully as\", output_path)\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while saving the image:\", e)\n",
    "\n",
    "# Example usage:\n",
    "background_path = \"Backgrounds/b3.jpg\"\n",
    "overlay_path = \"Raw shapes/circle1.png\"\n",
    "output_path = \"Overlayed/overlay1.jpg\"\n",
    "overlay_images(background_path, overlay_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_circles(100)\n",
    "gen_squares(100)\n",
    "gen_triangles(100)\n",
    "gen_pentagons(100)\n",
    "gen_hexagons(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,101,1):\n",
    "    background_path = \"Backgrounds/b3.jpg\"\n",
    "    overlay_path = \"Raw shapes/circle\" + str(i) + \".png\"\n",
    "    output_path = \"Data/circle\" + str(i) + \".jpg\"\n",
    "    overlay_images(background_path, overlay_path, output_path)\n",
    "for i in range(1,101,1):\n",
    "    background_path = \"Backgrounds/b3.jpg\"\n",
    "    overlay_path = \"Raw shapes/square\" + str(i) + \".png\"\n",
    "    output_path = \"Data/square\" + str(i) + \".jpg\"\n",
    "    overlay_images(background_path, overlay_path, output_path)\n",
    "for i in range(1,101,1):\n",
    "    background_path = \"Backgrounds/b3.jpg\"\n",
    "    overlay_path = \"Raw shapes/triangle\" + str(i) + \".png\"\n",
    "    output_path = \"Data/triangle\" + str(i) + \".jpg\"\n",
    "    overlay_images(background_path, overlay_path, output_path)\n",
    "for i in range(1,101,1):\n",
    "    background_path = \"Backgrounds/b3.jpg\"\n",
    "    overlay_path = \"Raw shapes/pentagon\" + str(i) + \".png\"\n",
    "    output_path = \"Data/pentagon\" + str(i) + \".jpg\"\n",
    "    overlay_images(background_path, overlay_path, output_path)\n",
    "for i in range(1,101,1):\n",
    "    background_path = \"Backgrounds/b3.jpg\"\n",
    "    overlay_path = \"Raw shapes/hexagon\" + str(i) + \".png\"\n",
    "    output_path = \"Data/hexagon\" + str(i) + \".jpg\"\n",
    "    overlay_images(background_path, overlay_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.zeros((500,2)))\n",
    "\n",
    "for i in range(100):\n",
    "    df.iat[i,0] = \"circle\" + str(i+1) + \".jpg\"\n",
    "    df.iat[i,1] = 0\n",
    "\n",
    "for i in range(100):\n",
    "    df.iat[i+100,0] = \"square\" + str(i+1) + \".jpg\"\n",
    "    df.iat[i+100,1] = 1\n",
    "\n",
    "for i in range(100):\n",
    "    df.iat[i+200,0] = \"triangle\" + str(i+1) + \".jpg\"\n",
    "    df.iat[i+200,1] = 2\n",
    "\n",
    "for i in range(100):\n",
    "    df.iat[i+300,0] = \"pentagon\" + str(i+1) + \".jpg\"\n",
    "    df.iat[i+300,1] = 3\n",
    "\n",
    "for i in range(100):\n",
    "    df.iat[i+400,0] = \"hexagon\" + str(i+1) + \".jpg\"\n",
    "    df.iat[i+400,1] = 4\n",
    "\n",
    "df.to_csv(\"data.csv\",index=False,header=False)\n",
    "\n",
    "# circle = 0\n",
    "# square = 1\n",
    "# triangle = 2\n",
    "# pentagon = 3\n",
    "# hexagon = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "labels_map = {\n",
    "    0: \"Circle\",\n",
    "    1: \"Square\",\n",
    "    2: \"Triangle\",\n",
    "    3: \"Pentagon\",\n",
    "    4: \"Hexagon\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"Data/\"\n",
    "annotations_file = \"data.csv\"\n",
    "dataset = CustomImageDataset(annotations_file=annotations_file,img_dir=img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.float()\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True) # WRONG, testing\n",
    "test_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 8, 5, 5], expected input[64, 6, 110, 110] to have 8 channels, but got 6 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[142], line 14\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[1;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 8, 5, 5], expected input[64, 6, 110, 110] to have 8 channels, but got 6 channels instead"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x100352 and 131072x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data, batch_targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 29\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[0;32m     31\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[126], line 29\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m input_size \u001b[38;5;241m=\u001b[39m num_channels \u001b[38;5;241m*\u001b[39m height \u001b[38;5;241m*\u001b[39m width\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, input_size)\n\u001b[1;32m---> 29\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\murra\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x100352 and 131072x256)"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}/{k}\")\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    train_data = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_data = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = model  # Replace YourModelHere with your model class\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10  # Define the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        for batch_data, batch_targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_targets in val_loader:\n",
    "                outputs = model(batch_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += batch_targets.size(0)\n",
    "                correct += (predicted == batch_targets).sum().item()\n",
    "                val_loss += criterion(outputs, batch_targets).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss}, Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
